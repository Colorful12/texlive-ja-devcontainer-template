\chapter{Introduction}
\section{Aim and Motivation} 
 This work makes the attempt to explore a path towards creating artificial
agents that can play the game of Pokemon on competitive levels through
methods of deep reinforcement learning. 

There are several motivations behind this goal. First of all, reinforcement
    learning(RL) has proposed a extremely powerful paradigm to create
    artificial intelligence, especially when paired with the representation
    power of deep neural networks. Since AlphaGO beat the human
    world champion in the game of Go in 2016, which is considered before to be
    impossible before by many scholars, RL is becoming increasingly active and
    promising as a research area. Some researchers even argues that the
    framework of RL is enough for intelligence of arbitrary complexity to arise
    in a recent publication . The reality is, despite the
    promises, that RL methods often suffer to perform or requires painfully
    time-consuming hyperparameter tuning in any task that is not a perfect
    information video game. This thesis, in the large picture, attempts to help
    closing the gap between theoretical promise and applicable reality of RL. 

This work also has an aspect of exploring possible solutions to 2 player
    imperfect-information games. Games are goal-oriented models of the real
    world, e.g. chess models a battle between two armies with different pieces
    representing different roles that exist in the real world.  The ideas
    represented by chess pieces are rather abstract, but human beings usually
    have no problem understanding the abstraction.  Recently, with the
    advancement of computer graphics, modern video games can now create almost
    photo-realistic gaming experience that, arguably, rivals the real world
    experience in complexity and intensity. Both classic board games and modern
    video games are goal-oriented and almost all of them can be played on a
    computer, which makes them the perfect test ground for artificial
    intelligence. Imperfect information games that require long term
    strategies, is one category of games that is much less studies compared to
    its perfect-information counterpart. Studying how imperfect-information
    games can be solved, using the case of Pokemon, records to be the second
    motivation of this thesis.
    
And last but certainly not least, as a long time Pokemon player myself, I
personally hold strong romantic values in the idea of creating something that
is better than myself in the game I love. The topic of the thesis is decided to
be such for the reasons discuss.

\section{Pokemon}
\begin{figure}
  \centering
  
    \caption{Screenshot of the Grand Finals of the Pokemon Video Game Championships 2019 held in Washinton D.C.}
\end{figure}
Pokemon as a franchise needs little introduction, as it is almost impossible to
find a person who has never heard of it, at least here in Japan. Pokemon Sword
and Sheild, the lastest iteration of the core series video games alone, has
sold more than 20,000,000 copies since its release in 2019, making it one of
the top-selling titles on the Nintendo Switch. Besides video games, Pokemon
also has massive success in its anime series, manga, movie and merchandise
sells, earning a estimated total revenue of more than 100 billion USD as for
2021, making it the most valuable multi-media franchise in the history, right
behind other big names like Mickey Mouse, Star Wars and so on.

Despite the wide exposure of the brand, only a few has really dug down into the
extremely complicated and fascinating core battle mechanics of the main series
video game of Pokemon. The experience of playing the game was well summarized
by the 2016 Pokemon world champion as "It is like a mixture of chess and poker,
but much more complicated.", characterizing the long-term strategizing and
partial observability, two of the defining features of the game. Competitive
Pokemon has gained increasing attention as a e-sports. The Pokemon Company
holds annual World Championship tournaments of the Pokemon video game and in
recent years, the world finals has recorded some truly amazing skills of top
human players to adjust game plans and taking risks that would finally lead to
victories.

\section{Overview of Thesis}
This thesis consist of 6 chapters, including this introduction chapter.
 pre explains some lower level building block
technologies used in this work including what is reinforcement learning, what
is a neural network and such. Chapter 3  introduces a selection
of recent researches including some state-of-the-art that this work took
inspiration from. Chapter 4explains the proposed methodologies
followed by Chapter which details the exact experiment setup
and presents the results. Finally in we will draw high
level conclusions of the whole thesis.

